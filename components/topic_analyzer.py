# components/topic_analyzer.py

import streamlit as st
import pandas as pd
import tomotopy as tp
import numpy as np
import matplotlib.pyplot as plt
# from kneed import KneeLocator  <- ì´ ë¶€ë¶„ì€ ì´ì œ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
import warnings
import ast

# í•œê¸€ í°íŠ¸ ì„¤ì •
try:
    import koreanize_matplotlib
except ImportError:
    st.error("koreanize_matplotlib ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install koreanize_matplotlib` ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings("ignore", category=RuntimeWarning)
warnings.filterwarnings("ignore", category=FutureWarning)


# --- ê³„ì‚° í•¨ìˆ˜ë“¤ ---

def calculate_log_likelihoods(corpus, progress_bar, status_text, train_steps=500, seed=100):
    """Log-likelihood ê³„ì‚° (Streamlit UI ì—…ë°ì´íŠ¸ ê¸°ëŠ¥ ì¶”ê°€)"""
    ntopics = []
    log_likelihoods = []
    total_steps = 20
    
    for k in range(1, total_steps + 1):
        progress = k / total_steps
        progress_bar.progress(progress)
        status_text.text(f"Log-likelihood ê³„ì‚° ì¤‘... (k={k}/{total_steps})")

        mdl = tp.LDAModel(k=k, seed=seed)
        for doc in corpus:
            mdl.add_doc(doc)
        mdl.burn_in = 50
        mdl.train(train_steps, workers=1)
        ntopics.append(k)
        log_likelihoods.append(mdl.ll_per_word)
    
    status_text.text("Log-likelihood ê³„ì‚° ì™„ë£Œ!")
    return ntopics, log_likelihoods

def calculate_coherence(corpus, progress_bar, status_text, k_start=2, k_end=20, train_steps=500, seed=100):
    """Coherence ì ìˆ˜ ê³„ì‚° (Streamlit UI ì—…ë°ì´íŠ¸ ê¸°ëŠ¥ ì¶”ê°€)"""
    ntopics = []
    coherence_scores = []
    total_steps = k_end - k_start + 1
    
    for i, k in enumerate(range(k_start, k_end + 1)):
        progress = (i + 1) / total_steps
        progress_bar.progress(progress)
        status_text.text(f"Coherence ì ìˆ˜ ê³„ì‚° ì¤‘... (k={k}/{k_end})")

        mdl = tp.LDAModel(k=k, seed=seed, tw=tp.TermWeight.PMI)
        for doc in corpus:
            mdl.add_doc(doc)
        mdl.burn_in = 50
        mdl.train(train_steps, workers=1)
        
        coh = tp.coherence.Coherence(mdl, coherence='c_v')
        coherence_value = coh.get_score()
        ntopics.append(k)
        coherence_scores.append(coherence_value)

    status_text.text("Coherence ì ìˆ˜ ê³„ì‚° ì™„ë£Œ!")
    return ntopics, coherence_scores

def safe_str_to_list(s):
    try:
        return ast.literal_eval(str(s))
    except (ValueError, SyntaxError):
        return str(s).split()


# --- ë©”ì¸ UI í•¨ìˆ˜ ---

def show():
    st.header("[5ë‹¨ê³„] ê°œë²½ í† í”½ ì¶”ì¶œ ðŸ’«")
    
    st.info("í† í”½ ëª¨ë¸ë§(LDA)ì„ í†µí•´ ë¬¸ì„œ ì§‘í•©ì˜ ì£¼ìš” ì£¼ì œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ìµœì ì˜ í† í”½ ê°œìˆ˜(k)ë¥¼ ì°¾ê¸° ìœ„í•œ ë‘ ê°€ì§€ ì§€í‘œë¥¼ ê³„ì‚°í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.")

    uploaded_file = st.file_uploader(
        "ë¶„ì„í•  ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (ì „ì²˜ë¦¬ ì™„ë£Œëœ 'doc_split_12gram' ì»¬ëŸ¼ í•„ìš”)", 
        type=['xlsx', 'xls']
    )

    if uploaded_file:
        try:
            gb_df = pd.read_excel(uploaded_file)
            if 'doc_split_12gram' not in gb_df.columns:
                st.error("'doc_split_12gram' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return
            
            gb_df['doc_split_12gram'] = gb_df['doc_split_12gram'].apply(safe_str_to_list)
            corpus = gb_df['doc_split_12gram'].to_list()
            st.success(f"íŒŒì¼ ë¡œë”© ì™„ë£Œ! ì´ {len(corpus)}ê°œì˜ ë¬¸ì„œê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # --- ìµœì  í† í”½ ìˆ˜ íƒìƒ‰ ì„¹ì…˜ ---
            st.subheader("1. ìµœì  í† í”½ ìˆ˜(k) íƒìƒ‰")
            st.markdown("""
            ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë‘ ê°€ì§€ ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ìµœì ì˜ í† í”½ ìˆ˜ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
            - **ëª¨ë¸ í˜¼ìž¡ë„ (Log-likelihood):** ê°’ì´ ê°€ìž¥ ë‚®ì€ ì§€ì  (Minimum point)ì´ í›„ë³´ê°€ ë©ë‹ˆë‹¤.
            - **í† í”½ ì¼ê´€ì„± (Coherence):** ê°’ì´ ê°€ìž¥ ë†’ì€ ì§€ì  (Peak point)ì´ ê°€ìž¥ ì¢‹ì€ í›„ë³´ìž…ë‹ˆë‹¤.
            """)

            col1, col2 = st.columns(2)

            # --- ëª¨ë¸ í˜¼ìž¡ë„ (Log-likelihood) ê°œë³„ ì‹¤í–‰ ---
            with col1:
                st.markdown("#### ëª¨ë¸ í˜¼ìž¡ë„ (Log-likelihood)")
                if st.button("í˜¼ìž¡ë„ ê³„ì‚° ì‹œìž‘"):
                    with st.spinner('Log-likelihood ê³„ì‚° ì¤‘...'):
                        ll_progress = st.progress(0)
                        ll_status = st.empty()
                        ntopics_ll, log_likelihoods = calculate_log_likelihoods(corpus, ll_progress, ll_status)
                        
                        st.session_state.log_likelihood_results = pd.DataFrame({
                            'k': ntopics_ll,
                            'Log-likelihood': log_likelihoods
                        }).set_index('k')

            if 'log_likelihood_results' in st.session_state:
                with col1:
                    st.write("##### ê³„ì‚° ê²°ê³¼")
                    st.dataframe(st.session_state.log_likelihood_results)

                    fig1, ax1 = plt.subplots(figsize=(10, 6))
                    ax1.plot(st.session_state.log_likelihood_results.index, st.session_state.log_likelihood_results['Log-likelihood'], marker='o', linestyle='--')
                    ax1.set_xlabel("Number of topics (k)")
                    ax1.set_ylabel("Log-likelihood")
                    ax1.set_title("Log-likelihood per Number of Topics")
                    ax1.set_xticks(st.session_state.log_likelihood_results.index)
                    ax1.grid(True, alpha=0.5)
                    st.pyplot(fig1)
                    
                    # --- âœ¨ ë³€ê²½ì : ê°€ìž¥ ë‚®ì€ ì§€ì (Minimum Point) ê³„ì‚° ë° í‘œì‹œ ---
                    min_point_k = st.session_state.log_likelihood_results['Log-likelihood'].idxmin()
                    st.success(f"í˜¼ìž¡ë„ ê¸°ë°˜ ì¶”ì²œ k (ìµœì €ì ): **{min_point_k}**")


            # --- í† í”½ ì¼ê´€ì„± (Coherence) ê°œë³„ ì‹¤í–‰ ---
            with col2:
                st.markdown("#### í† í”½ ì¼ê´€ì„± (Coherence Score)")
                if st.button("ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚° ì‹œìž‘"):
                    with st.spinner('Coherence ì ìˆ˜ ê³„ì‚° ì¤‘...'):
                        coh_progress = st.progress(0)
                        coh_status = st.empty()
                        ntopics_coh, coherence_scores = calculate_coherence(corpus, coh_progress, coh_status)

                        st.session_state.coherence_results = pd.DataFrame({
                            'k': ntopics_coh,
                            'Coherence (c_v)': coherence_scores
                        }).set_index('k')
            
            if 'coherence_results' in st.session_state:
                with col2:
                    st.write("##### ê³„ì‚° ê²°ê³¼")
                    st.dataframe(st.session_state.coherence_results)

                    coh_results_df = st.session_state.coherence_results
                    best_k = coh_results_df['Coherence (c_v)'].idxmax()
                    
                    fig3, ax3 = plt.subplots(figsize=(12, 6))
                    ax3.plot(coh_results_df.index, coh_results_df['Coherence (c_v)'], marker='o', linestyle='--', color='mediumseagreen', label='Topic Coherence (c_v)')
                    ax3.axvline(x=best_k, color='tomato', linestyle=':', linewidth=2, label=f'Best k = {best_k}')
                    ax3.set_xlabel("Number of Topics(k)")
                    ax3.set_ylabel("Coherence Score (c_v)")
                    ax3.set_title("Coherence Score by Number of Topics")
                    ax3.set_xticks(coh_results_df.index)
                    ax3.legend()
                    st.pyplot(fig3)
                    st.success(f"ì¼ê´€ì„± ê¸°ë°˜ ì¶”ì²œ k (Peak): **{best_k}**")

        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.warning("ì—‘ì…€ íŒŒì¼ì˜ 'doc_split_12gram' ì»¬ëŸ¼ ë‚´ìš©ì´ `['ë‹¨ì–´1', 'ë‹¨ì–´2']` ì™€ ê°™ì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë˜ì–´ìžˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")