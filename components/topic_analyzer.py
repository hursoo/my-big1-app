# components/topic_analyzer.py

import streamlit as st
import pandas as pd
import tomotopy as tp
import numpy as np
import matplotlib.pyplot as plt
from kneed import KneeLocator
import warnings
import ast  # âœ¨ 1. ast ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.

# í•œê¸€ í°íŠ¸ ì„¤ì •
try:
    import koreanize_matplotlib
except ImportError:
    st.error("koreanize_matplotlib ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install koreanize_matplotlib` ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings("ignore", category=RuntimeWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

# --- ê³„ì‚° í•¨ìˆ˜ë“¤ (ì‚¬ìš©ì ì½”ë“œ ê¸°ë°˜) ---

def calculate_log_likelihoods(corpus, progress_bar, status_text, train_steps=500, seed=100):
    """Log-likelihood ê³„ì‚° (Streamlit UI ì—…ë°ì´íŠ¸ ê¸°ëŠ¥ ì¶”ê°€)"""
    ntopics = []
    log_likelihoods = []
    total_steps = 20
    
    for k in range(1, total_steps + 1):
        # UI ì—…ë°ì´íŠ¸
        progress = k / total_steps
        progress_bar.progress(progress)
        status_text.text(f"Log-likelihood ê³„ì‚° ì¤‘... (k={k}/{total_steps})")

        mdl = tp.LDAModel(k=k, seed=seed)
        for doc in corpus:
            mdl.add_doc(doc)
        mdl.burn_in = 50
        mdl.train(train_steps, workers=1)
        ntopics.append(k)
        log_likelihoods.append(mdl.ll_per_word)
    
    status_text.text("Log-likelihood ê³„ì‚° ì™„ë£Œ!")
    return ntopics, log_likelihoods

def calculate_coherence(corpus, progress_bar, status_text, k_start=2, k_end=20, train_steps=500, seed=100):
    """Coherence ì ìˆ˜ ê³„ì‚° (Streamlit UI ì—…ë°ì´íŠ¸ ê¸°ëŠ¥ ì¶”ê°€)"""
    ntopics = []
    coherence_scores = []
    total_steps = k_end - k_start + 1
    
    for i, k in enumerate(range(k_start, k_end + 1)):
        # UI ì—…ë°ì´íŠ¸
        progress = (i + 1) / total_steps
        progress_bar.progress(progress)
        status_text.text(f"Coherence ì ìˆ˜ ê³„ì‚° ì¤‘... (k={k}/{k_end})")

        mdl = tp.LDAModel(k=k, seed=seed, tw=tp.TermWeight.PMI)
        for doc in corpus:
            mdl.add_doc(doc)
        mdl.burn_in = 50
        mdl.train(train_steps, workers=1)
        
        coh = tp.coherence.Coherence(mdl, coherence='c_v')
        coherence_value = coh.get_score()
        ntopics.append(k)
        coherence_scores.append(coherence_value)

    status_text.text("Coherence ì ìˆ˜ ê³„ì‚° ì™„ë£Œ!")
    return ntopics, coherence_scores

# âœ¨ 2. ì–´ë–¤ ë°ì´í„° í˜•ì‹ì´ë“  ì•ˆì „í•˜ê²Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
def safe_str_to_list(s):
    try:
        # ë¬¸ìì—´ì´ "['a', 'b']" í˜•íƒœì¼ ê²½ìš°, ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ ['a', 'b']ë¡œ ë³€í™˜
        return ast.literal_eval(str(s))
    except (ValueError, SyntaxError):
        # ë³€í™˜ì— ì‹¤íŒ¨í•˜ë©´ (ì˜ˆ: "a b c" í˜•íƒœì˜ ì¼ë°˜ í…ìŠ¤íŠ¸), ê³µë°±ìœ¼ë¡œ ë‚˜ëˆ”
        return str(s).split()


# --- ë©”ì¸ UI í•¨ìˆ˜ ---

def show():
    st.header("[5ë‹¨ê³„] ê°œë²½ í† í”½ ì¶”ì¶œ ğŸ’«")
    
    st.info("í† í”½ ëª¨ë¸ë§(LDA)ì„ í†µí•´ ë¬¸ì„œ ì§‘í•©ì˜ ì£¼ìš” ì£¼ì œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ìµœì ì˜ í† í”½ ê°œìˆ˜(k)ë¥¼ ì°¾ê¸° ìœ„í•œ ë‘ ê°€ì§€ ì§€í‘œë¥¼ ê³„ì‚°í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.")

    # 1. íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "ë¶„ì„í•  ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (ì „ì²˜ë¦¬ ì™„ë£Œëœ 'doc_split_12gram' ì»¬ëŸ¼ í•„ìš”)", 
        type=['xlsx', 'xls']
    )

    if uploaded_file:
        try:
            gb_df = pd.read_excel(uploaded_file)
            if 'doc_split_12gram' not in gb_df.columns:
                st.error("'doc_split_12gram' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return
            
            # str í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            gb_df['doc_split_12gram'] = gb_df['doc_split_12gram'].apply(safe_str_to_list)
            corpus = gb_df['doc_split_12gram'].to_list()
            st.success(f"íŒŒì¼ ë¡œë”© ì™„ë£Œ! ì´ {len(corpus)}ê°œì˜ ë¬¸ì„œê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # 2. ìµœì  í† í”½ ìˆ˜ íƒìƒ‰
            st.subheader("1. ìµœì  í† í”½ ìˆ˜(k) íƒìƒ‰")
            st.markdown("""
            ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë‘ ê°€ì§€ ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ìµœì ì˜ í† í”½ ìˆ˜ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
            - **ëª¨ë¸ í˜¼ì¡ë„ (Log-likelihood):** ê°’ì´ ê¸‰ê²©íˆ êº¾ì´ëŠ” ì§€ì  (Elbow point)ì´ í›„ë³´ê°€ ë©ë‹ˆë‹¤.
            - **í† í”½ ì¼ê´€ì„± (Coherence):** ê°’ì´ ê°€ì¥ ë†’ì€ ì§€ì  (Peak point)ì´ ê°€ì¥ ì¢‹ì€ í›„ë³´ì…ë‹ˆë‹¤.
            """)

            if st.button("ìµœì  í† í”½ ìˆ˜ ê³„ì‚° ì‹œì‘ (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë©ë‹ˆë‹¤)"):
                
                col1, col2 = st.columns(2)

                # --- ëª¨ë¸ í˜¼ì¡ë„ (Log-likelihood) ---
                with col1:
                    st.markdown("#### ëª¨ë¸ í˜¼ì¡ë„ (Log-likelihood)")
                    with st.spinner('Log-likelihood ê³„ì‚° ì¤‘...'):
                        ll_progress = st.progress(0)
                        ll_status = st.empty()
                        ntopics_ll, log_likelihoods = calculate_log_likelihoods(corpus, ll_progress, ll_status)

                    # ì›ë³¸ ê·¸ë˜í”„
                    fig1, ax1 = plt.subplots(figsize=(10, 6))
                    ax1.plot(ntopics_ll, log_likelihoods, marker='o', linestyle='--')
                    ax1.set_xlabel("Number of topics (k)")
                    ax1.set_ylabel("Log-likelihood")
                    ax1.set_title("Log-likelihood per Number of Topics")
                    ax1.set_xticks(ntopics_ll)
                    ax1.grid(True, alpha=0.5)
                    st.pyplot(fig1)

                    # ë³€í™”ìœ¨ ê·¸ë˜í”„
                    loglikelihood_diff = np.diff(np.array(log_likelihoods))
                    kl = KneeLocator(x=ntopics_ll[1:], y=loglikelihood_diff, curve='concave', direction='increasing')
                    elbow_point = kl.elbow
                    st.success(f"í˜¼ì¡ë„ ê¸°ë°˜ ì¶”ì²œ k (Elbow): **{elbow_point}**")

                    fig2, ax2 = plt.subplots(figsize=(10, 6))
                    ax2.plot(ntopics_ll[1:], loglikelihood_diff, marker='o', label="Change in Log-likelihood")
                    if elbow_point:
                        ax2.axvline(x=elbow_point, color='red', linestyle='--', label=f"Elbow (k={elbow_point})")
                    ax2.set_xlabel('Number of Topics (k)')
                    ax2.set_ylabel('Change in Log-likelihood')
                    ax2.set_title('Change in Log-likelihood by Number of Topics')
                    ax2.grid(alpha=0.5)
                    ax2.legend()
                    st.pyplot(fig2)

                # --- í† í”½ ì¼ê´€ì„± (Coherence) ---
                with col2:
                    st.markdown("#### í† í”½ ì¼ê´€ì„± (Coherence Score)")
                    with st.spinner('Coherence ì ìˆ˜ ê³„ì‚° ì¤‘...'):
                        coh_progress = st.progress(0)
                        coh_status = st.empty()
                        ntopics_coh, coherence_scores = calculate_coherence(corpus, coh_progress, coh_status)

                    best_k_index = np.argmax(coherence_scores)
                    best_k = ntopics_coh[best_k_index]
                    st.success(f"ì¼ê´€ì„± ê¸°ë°˜ ì¶”ì²œ k (Peak): **{best_k}**")

                    fig3, ax3 = plt.subplots(figsize=(12, 6))
                    ax3.plot(ntopics_coh, coherence_scores, marker='o', linestyle='--', color='mediumseagreen', label='Topic Coherence (c_v)')
                    ax3.axvline(x=best_k, color='tomato', linestyle=':', linewidth=2, label=f'Best k = {best_k}')
                    ax3.set_xlabel("Number of Topics(k)")
                    ax3.set_ylabel("Coherence Score (c_v)")
                    ax3.set_title("Coherence Score by Number of Topics")
                    ax3.set_xticks(ntopics_coh)
                    ax3.legend()
                    st.pyplot(fig3)

        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.warning("ì—‘ì…€ íŒŒì¼ì˜ 'doc_split_12gram' ì»¬ëŸ¼ ë‚´ìš©ì´ `['ë‹¨ì–´1', 'ë‹¨ì–´2']` ì™€ ê°™ì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë˜ì–´ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")