import streamlit as st
import pandas as pd
import ssl
from urllib.request import urlopen
from bs4 import BeautifulSoup
import io

@st.cache_data
def convert_df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    return output.getvalue()

def get_contents(urls, n):
    results = []
    progress_bar = st.progress(0, text="ìŠ¤í¬ë˜í•‘ ì§„í–‰ ì¤‘...")
    ctx = ssl._create_unverified_context()

    for i, url in enumerate(urls[:n]):
        try:
            webpage = urlopen(url, context=ctx)
            r_id = url[-16:]
            bsobj = BeautifulSoup(webpage.read(), 'lxml')
            List1 = bsobj.find_all('div', {'id': 'cont_view'})
            for z in List1:
                z1 = z.get_text('\n', strip=True)
                results.append([r_id, z1])
        except Exception as e:
            st.warning(f"{url} ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue
        
        progress_bar.progress((i + 1) / n, text=f"ìŠ¤í¬ë˜í•‘ ì§„í–‰ ì¤‘... ({i+1}/{n})")
    
    progress_bar.empty()
    return pd.DataFrame(results, columns=['r_id', 'content'])

def show():
    st.header("ìë£Œ ë¶ˆëŸ¬ì˜¤ê¸° ë° ìŠ¤í¬ë˜í•‘")
    st.info("ë…¼ì„¤ ì •ë³´ ì—‘ì…€ íŒŒì¼ê³¼ ê¸°ì‚¬ ì •ë³´ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•˜ì„¸ìš”.")

    # --- 1. íŒŒì¼ ì—…ë¡œë“œ UI (í•­ìƒ í‘œì‹œ) ---
    col1, col2 = st.columns(2)
    ron_info_df = None
    with col1:
        excel_file = st.file_uploader("ë…¼ì„¤ ì •ë³´(`ron_info` ì‹œíŠ¸ í¬í•¨) ì—‘ì…€ íŒŒì¼", type=['xlsx', 'xls'])
        if excel_file:
            try:
                xls = pd.ExcelFile(excel_file)
                if 'ron_info' in xls.sheet_names:
                    ron_info_df = pd.read_excel(xls, sheet_name='ron_info')
                    st.dataframe(ron_info_df.head(2), use_container_width=True)
                else: 
                    st.error("'ron_info' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    with col2:
        gisa_file = st.file_uploader("ê¸°ì‚¬ ì •ë³´(`...txt`) íŒŒì¼", type="txt")
        if gisa_file:
            try:
                gisa_info_df = pd.read_csv(gisa_file, sep='^', encoding='utf-8')
                st.dataframe(gisa_info_df.head(2), use_container_width=True)
            except Exception as e:
                st.error(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    # --- 2. ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ UI (ì—‘ì…€ ë¡œë“œ ì‹œ í•­ìƒ í‘œì‹œ) ---
    if ron_info_df is not None:
        st.divider()
        st.subheader("ìŠ¤í¬ë˜í•‘ ì‹¤í–‰")
        urls = ron_info_df['url'].tolist()
        num_to_scrape = st.slider("ìŠ¤í¬ë˜í•‘í•  ë…¼ì„¤ ê°œìˆ˜", 1, len(urls), min(10, len(urls)))

        if st.button("ì›¹ ìŠ¤í¬ë˜í•‘ ë° ë°ì´í„° ê²°í•© ì‹œì‘", type="primary"):
            if gisa_file is None:
                st.error("ê¸°ì‚¬ ì •ë³´(txt) íŒŒì¼ë„ í•¨ê»˜ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                with st.spinner("ì‘ì—…ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
                    # ìŠ¤í¬ë˜í•‘ ë° ê²°í•© ë¡œì§
                    contents_df = get_contents(urls, num_to_scrape)
                    r334_info1 = ron_info_df.drop('r_id', axis=1, errors='ignore')
                    combi_df = pd.merge(r334_info1, contents_df, left_on='r_id_raw', right_on='r_id', how='inner')
                    combi_df1 = combi_df[['r_id', 'r_id_raw', 'title', 'writer', 'gisa_class', 'date', 'url', 'year', 'content']]
                    # ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                    st.session_state.scraped_df = combi_df1
    
    st.divider()

    # --- 3. ê²°ê³¼ í‘œì‹œ UI (ì„¸ì…˜ì— ê²°ê³¼ê°€ ìˆì„ ë•Œ í•­ìƒ í‘œì‹œ) ---
    if 'scraped_df' in st.session_state and st.session_state.scraped_df is not None:
        st.subheader("ì‘ì—… ê²°ê³¼")
        st.success("ìŠ¤í¬ë˜í•‘ ë° ê²°í•© ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.dataframe(st.session_state.scraped_df, use_container_width=True)
        
        excel_data = convert_df_to_excel(st.session_state.scraped_df)
        st.download_button(
            "ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)",
            excel_data,
            'scraped_data.xlsx',
            'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
        
        # ê²°ê³¼ë¬¼ì„ ì§€ìš°ê³  ë‹¤ì‹œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” ë¦¬ì…‹ ë²„íŠ¼
        if st.button("ğŸ”„ ê²°ê³¼ ì§€ìš°ê³  ìƒˆë¡œ ì‹œì‘í•˜ê¸°"):
            del st.session_state.scraped_df
            st.rerun()